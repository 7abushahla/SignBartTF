{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SignBART Functional Model - QAT Experimentation\n",
        "\n",
        "This notebook lets you experiment with:\n",
        "1. Loading and inspecting the functional model\n",
        "2. Selective layer annotation for QAT\n",
        "3. Applying quantization with different strategies\n",
        "4. Comparing model sizes and accuracy\n",
        "\n",
        "Once you find a good strategy, we'll integrate it into the training script.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "from model_functional import build_signbart_functional_with_dict_inputs\n",
        "from layers import Projection, ClassificationHead, PositionalEmbedding\n",
        "from encoder import Encoder, EncoderLayer\n",
        "from decoder import Decoder, DecoderLayer\n",
        "from attention import SelfAttention, CrossAttention, CausalSelfAttention\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"Keras version: {keras.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Model Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load config\n",
        "config_path = \"configs/arabic-asl-90kpts.yaml\"\n",
        "\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "print(\"Model Configuration:\")\n",
        "print(f\"  d_model: {config['d_model']}\")\n",
        "print(f\"  encoder_layers: {config['encoder_layers']}\")\n",
        "print(f\"  decoder_layers: {config['decoder_layers']}\")\n",
        "print(f\"  num_labels: {config['num_labels']}\")\n",
        "print(f\"  joint_idx: {len(config['joint_idx'])} keypoints\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Build Functional Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build model with FULLY FUNCTIONAL architecture\n",
        "print(\"Building functional model (with functional Encoder/Decoder)...\")\n",
        "model = build_signbart_functional_with_dict_inputs(config)\n",
        "\n",
        "# Test with dummy input\n",
        "num_keypoints = len(config['joint_idx'])\n",
        "dummy_input = {\n",
        "    'keypoints': tf.random.normal((1, 10, num_keypoints, 2)),\n",
        "    'attention_mask': tf.ones((1, 10))\n",
        "}\n",
        "output = model(dummy_input, training=False)\n",
        "\n",
        "print(f\"‚úì Model built successfully\")\n",
        "print(f\"  Output shape: {output.shape}\")\n",
        "print(f\"\\nüìä Model uses FULLY FUNCTIONAL Encoder & Decoder\")\n",
        "print(f\"   This means each component has proper .summary() and Netron visualization!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.5 Component-Level Inspection\n",
        "\n",
        "Now let's look at each component separately. Since Encoder and Decoder are now **Functional Models**, they have proper `.summary()` methods!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from encoder import build_encoder_functional, EncoderLayer\n",
        "from decoder import build_decoder_functional, DecoderLayer\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"COMPONENT 1: ENCODER (Functional Model)\")\n",
        "print(\"=\"*80)\n",
        "encoder_model = build_encoder_functional(config)\n",
        "encoder_model.summary(line_length=100)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Drilling into Encoder's EncoderLayer (Custom Layer):\")\n",
        "print(\"=\"*80)\n",
        "# EncoderLayer is a custom Layer (not a Model), but we can still see what's inside\n",
        "for layer in encoder_model.layers:\n",
        "    if isinstance(layer, EncoderLayer):\n",
        "        print(f\"\\nüì¶ {layer.name} contains:\")\n",
        "        print(f\"  - self_attn: {type(layer.self_attn).__name__}\")\n",
        "        print(f\"  - fc1 (Dense): {layer.fc1.units} units\")\n",
        "        print(f\"  - fc2 (Dense): {layer.fc2.units} units\") \n",
        "        print(f\"  - 2 LayerNorms, 2 Dropouts\")\n",
        "        print(f\"  ‚Üí We can access layer.fc1 and layer.fc2 for selective quantization!\")\n",
        "        break\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"COMPONENT 2: DECODER (Functional Model)\")\n",
        "print(\"=\"*80)\n",
        "decoder_model = build_decoder_functional(config)\n",
        "decoder_model.summary(line_length=100)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Drilling into Decoder's DecoderLayer (Custom Layer):\")\n",
        "print(\"=\"*80)\n",
        "for layer in decoder_model.layers:\n",
        "    if isinstance(layer, DecoderLayer):\n",
        "        print(f\"\\nüì¶ {layer.name} contains:\")\n",
        "        print(f\"  - self_attn (causal): {type(layer.self_attn).__name__}\")\n",
        "        print(f\"  - encoder_attn (cross): {type(layer.encoder_attn).__name__}\")\n",
        "        print(f\"  - fc1 (Dense): {layer.fc1.units} units\")\n",
        "        print(f\"  - fc2 (Dense): {layer.fc2.units} units\")\n",
        "        print(f\"  - 3 LayerNorms, 3 Dropouts\")\n",
        "        print(f\"  ‚Üí We can access layer.fc1 and layer.fc2 for selective quantization!\")\n",
        "        break\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"ARCHITECTURE HIERARCHY\")\n",
        "print(\"=\"*80)\n",
        "print(\"‚úì Level 1: SignBART (Functional Model)\")\n",
        "print(\"  ‚úì Level 2: Encoder (Functional Model)\")\n",
        "print(\"    ‚Ä¢ Level 3: EncoderLayer (Custom Layer with Dense layers inside)\")\n",
        "print(\"  ‚úì Level 2: Decoder (Functional Model)\")  \n",
        "print(\"    ‚Ä¢ Level 3: DecoderLayer (Custom Layer with Dense layers inside)\")\n",
        "print(\"  ‚Ä¢ Level 2: Projection, ClassificationHead (Custom Layers)\")\n",
        "print(\"\\nThis is STANDARD Keras pattern - Model ‚Üí Model ‚Üí Layer\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.7 Verifying the Encoder-Decoder Connection\n",
        "\n",
        "Let's verify that the Encoder and Decoder are properly connected in the computational graph:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*100)\n",
        "print(\"ENCODER-DECODER CONNECTION IN SIGNBART\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "# Extract encoder and decoder from the full model\n",
        "encoder = None\n",
        "decoder = None\n",
        "\n",
        "for layer in model.layers:\n",
        "    if 'encoder' in layer.name.lower() and hasattr(layer, 'summary'):\n",
        "        encoder = layer\n",
        "    if 'decoder' in layer.name.lower() and hasattr(layer, 'summary'):\n",
        "        decoder = layer\n",
        "\n",
        "if encoder and decoder:\n",
        "    print(\"\\n‚úì Found Encoder and Decoder as functional Models within SignBART\")\n",
        "    print(f\"\\nEncoder: {encoder.name}\")\n",
        "    print(f\"  Inputs: {[inp.name for inp in encoder.input.values()] if isinstance(encoder.input, dict) else [inp.name for inp in encoder.input]}\")\n",
        "    print(f\"  Output: {encoder.output.name}, shape: {encoder.output.shape}\")\n",
        "    \n",
        "    print(f\"\\nDecoder: {decoder.name}\")\n",
        "    print(f\"  Inputs: {[inp.name for inp in decoder.input.values()] if isinstance(decoder.input, dict) else [inp.name for inp in decoder.input]}\")\n",
        "    print(f\"  Output: {decoder.output.name}, shape: {decoder.output.shape}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"CONNECTION FLOW:\")\n",
        "    print(\"=\"*100)\n",
        "    print(\"1. Input keypoints ‚Üí Projection ‚Üí x_embed, y_embed\")\n",
        "    print(\"2. x_embed ‚Üí ENCODER ‚Üí encoder_hidden_states\")\n",
        "    print(\"3. encoder_hidden_states ‚Üí DECODER (cross-attention) ‚Üê CONNECTED!\")\n",
        "    print(\"4. y_embed ‚Üí DECODER (self-attention)\")\n",
        "    print(\"5. decoder_outputs ‚Üí ExtractLastToken ‚Üí ClassificationHead ‚Üí logits\")\n",
        "    print(\"=\"*100)\n",
        "    \n",
        "    print(\"\\n‚úì Encoder and Decoder are CONNECTED in the computational graph!\")\n",
        "    print(\"‚úì Decoder receives encoder outputs via 'encoder_hidden_states' input\")\n",
        "    print(\"‚úì This is the standard Transformer encoder-decoder architecture\")\n",
        "else:\n",
        "    print(\"‚ö† Could not find encoder/decoder models\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"HIERARCHY:\")\n",
        "print(\"=\"*100)\n",
        "print(\"SignBART (Functional Model)\")\n",
        "print(\"‚îú‚îÄ‚îÄ Projection (Custom Layer)\")\n",
        "print(\"‚îú‚îÄ‚îÄ Encoder (Functional Model) ‚Üê can call .summary()\")\n",
        "print(\"‚îÇ   ‚îî‚îÄ‚îÄ encoder_layer_0, encoder_layer_1... (Custom Layers)\")\n",
        "print(\"‚îÇ       ‚îî‚îÄ‚îÄ fc1, fc2 (Dense layers) ‚Üê can annotate for QAT\")\n",
        "print(\"‚îú‚îÄ‚îÄ Decoder (Functional Model) ‚Üê can call .summary()\")\n",
        "print(\"‚îÇ   ‚îî‚îÄ‚îÄ decoder_layer_0, decoder_layer_1... (Custom Layers)\")\n",
        "print(\"‚îÇ       ‚îî‚îÄ‚îÄ fc1, fc2 (Dense layers) ‚Üê can annotate for QAT\")\n",
        "print(\"‚îú‚îÄ‚îÄ ExtractLastValidToken (Custom Layer)\")\n",
        "print(\"‚îî‚îÄ‚îÄ ClassificationHead (Custom Layer)\")\n",
        "print(\"    ‚îî‚îÄ‚îÄ out_proj (Dense layer) ‚Üê can annotate for QAT\")\n",
        "print(\"=\"*100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.8 Full Model Summary\n",
        "\n",
        "Now let's see how everything connects together in the complete SignBART model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"FULL SIGNBART MODEL SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "model.summary(line_length=100)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"KEY OBSERVATIONS\")\n",
        "print(\"=\"*80)\n",
        "print(\"‚úì Encoder and Decoder are now MODELS (not just Layers)\")\n",
        "print(\"‚úì Each component can be inspected independently\")\n",
        "print(\"‚úì Perfect for Netron visualization\")\n",
        "print(\"‚úì Better for selective quantization strategies\")\n",
        "print(\"‚úì More standard Keras architecture\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Inspect Nested Layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get nested layers\n",
        "projection = model.get_layer('projection')\n",
        "encoder = model.get_layer('encoder')\n",
        "decoder = model.get_layer('decoder')\n",
        "clf_head = model.get_layer('classification_head')\n",
        "\n",
        "def print_layer_info(layer, name):\n",
        "    \"\"\"Print layer information - works for both Model and Layer.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(name)\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    if hasattr(layer, 'summary'):\n",
        "        # It's a Model, can call summary\n",
        "        layer.summary()\n",
        "    else:\n",
        "        # It's a Layer, print manually\n",
        "        print(f\"Type: {layer.__class__.__name__}\")\n",
        "        if hasattr(layer, 'trainable_variables'):\n",
        "            total_params = sum([tf.size(w).numpy() for w in layer.trainable_variables])\n",
        "            print(f\"Trainable parameters: {total_params:,}\")\n",
        "            print(\"\\nWeights:\")\n",
        "            for w in layer.trainable_variables:\n",
        "                print(f\"  - {w.name}: {w.shape} ({tf.size(w).numpy():,} params)\")\n",
        "\n",
        "print_layer_info(projection, \"PROJECTION LAYER\")\n",
        "print_layer_info(encoder, \"ENCODER\")\n",
        "print_layer_info(decoder, \"DECODER\")\n",
        "print_layer_info(clf_head, \"CLASSIFICATION HEAD\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Find All Dense Layers (What Can Be Quantized)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. QAT Approaches - Finding What Works\n",
        "\n",
        "Let's test different QAT approaches to see which one works with our nested architecture.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*100)\n",
        "print(\"APPROACH 1: Using quantize_model() directly (simplest)\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "try:\n",
        "    # Try the simplest approach - let tfmot handle everything\n",
        "    qat_model_simple = tfmot.quantization.keras.quantize_model(model)\n",
        "    print(\"‚úì SUCCESS! quantize_model() works directly\")\n",
        "    print(f\"  Total params: {qat_model_simple.count_params():,}\")\n",
        "    \n",
        "    # Test forward pass\n",
        "    test_output = qat_model_simple(dummy_input, training=False)\n",
        "    print(f\"‚úì Forward pass works, output shape: {test_output.shape}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå FAILED: {type(e).__name__}: {e}\")\n",
        "    qat_model_simple = None\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*100)\n",
        "print(\"APPROACH 2: Using quantize_annotate_model() + quantize_apply()\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "try:\n",
        "    # Annotate all quantizable layers automatically\n",
        "    annotated_model = tfmot.quantization.keras.quantize_annotate_model(model)\n",
        "    print(\"‚úì Model annotated\")\n",
        "    \n",
        "    # Apply quantization\n",
        "    qat_model_annotate = tfmot.quantization.keras.quantize_apply(annotated_model)\n",
        "    print(\"‚úì SUCCESS! quantize_annotate_model() + quantize_apply() works\")\n",
        "    print(f\"  Total params: {qat_model_annotate.count_params():,}\")\n",
        "    \n",
        "    # Test forward pass\n",
        "    test_output = qat_model_annotate(dummy_input, training=False)\n",
        "    print(f\"‚úì Forward pass works, output shape: {test_output.shape}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå FAILED: {type(e).__name__}: {e}\")\n",
        "    qat_model_annotate = None\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*100)\n",
        "print(\"APPROACH 3: Manual recursive annotation (for selective quantization)\")\n",
        "print(\"=\"*100)\n",
        "print(\"This is needed when you want to quantize ONLY specific layers\")\n",
        "print(\"(e.g., only Dense layers in FFN, not in attention)\")\n",
        "\n",
        "try:\n",
        "    def annotate_layer_recursive(layer):\n",
        "        \"\"\"\n",
        "        Recursively annotate layers.\n",
        "        For custom layers with nested Dense layers, we need to traverse into them.\n",
        "        \"\"\"\n",
        "        # If it's a Dense layer, annotate it\n",
        "        if isinstance(layer, keras.layers.Dense):\n",
        "            print(f\"  Annotating: {layer.name}\")\n",
        "            return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "        \n",
        "        # If it's a Model (functional), clone it recursively\n",
        "        if isinstance(layer, keras.Model):\n",
        "            print(f\"  Traversing Model: {layer.name}\")\n",
        "            return keras.models.clone_model(\n",
        "                layer,\n",
        "                clone_function=annotate_layer_recursive\n",
        "            )\n",
        "        \n",
        "        # For custom Layer subclasses (like EncoderLayer, Projection), \n",
        "        # tfmot will NOT automatically traverse into them with clone_model\n",
        "        # We return them as-is, but tfmot's quantize_annotate_model DOES traverse\n",
        "        return layer\n",
        "    \n",
        "    print(\"\\nStep 1: Annotating model...\")\n",
        "    # Use quantize_annotate_model which handles nested layers better\n",
        "    annotated = tfmot.quantization.keras.quantize_annotate_model(model)\n",
        "    \n",
        "    print(\"\\nStep 2: Applying quantization...\")\n",
        "    qat_model_manual = tfmot.quantization.keras.quantize_apply(annotated)\n",
        "    \n",
        "    print(\"‚úì SUCCESS! Manual approach works\")\n",
        "    print(f\"  Total params: {qat_model_manual.count_params():,}\")\n",
        "    \n",
        "    # Test forward pass\n",
        "    test_output = qat_model_manual(dummy_input, training=False)\n",
        "    print(f\"‚úì Forward pass works, output shape: {test_output.shape}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå FAILED: {type(e).__name__}: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    qat_model_manual = None\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*100)\n",
        "print(\"SUMMARY: Which QAT Approach Works?\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "approaches = [\n",
        "    (\"Approach 1: quantize_model()\", qat_model_simple),\n",
        "    (\"Approach 2: quantize_annotate_model() + quantize_apply()\", qat_model_annotate),\n",
        "    (\"Approach 3: Manual recursive\", qat_model_manual),\n",
        "]\n",
        "\n",
        "for name, model_obj in approaches:\n",
        "    status = \"‚úì WORKS\" if model_obj is not None else \"‚ùå FAILED\"\n",
        "    print(f\"{status}: {name}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"RECOMMENDATION:\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "if qat_model_simple is not None:\n",
        "    print(\"‚úì Use Approach 1: tfmot.quantization.keras.quantize_model(model)\")\n",
        "    print(\"  - Simplest (one line!)\")\n",
        "    print(\"  - Automatically handles nested layers\")\n",
        "    print(\"  - Quantizes all quantizable layers (Dense, Conv2D, etc.)\")\n",
        "    selected_qat_model = qat_model_simple\n",
        "elif qat_model_annotate is not None:\n",
        "    print(\"‚úì Use Approach 2: quantize_annotate_model() + quantize_apply()\")\n",
        "    print(\"  - Simple (two lines)\")\n",
        "    print(\"  - Good for when quantize_model() doesn't work\")\n",
        "    selected_qat_model = qat_model_annotate\n",
        "else:\n",
        "    print(\"‚ö† Approaches 1 & 2 failed - you'll need custom logic\")\n",
        "    print(\"  This means tfmot doesn't recognize your layer structure\")\n",
        "    print(\"  You may need to refactor custom layers or use a custom QuantizeConfig\")\n",
        "    selected_qat_model = None\n",
        "\n",
        "print(\"=\"*100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.1 Why `clone_model()` Alone Doesn't Work\n",
        "\n",
        "**The Problem:**\n",
        "```python\n",
        "# This FAILS ‚ùå\n",
        "def annotate_dense(layer):\n",
        "    if isinstance(layer, keras.layers.Dense):\n",
        "        return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "    return layer\n",
        "\n",
        "annotated = keras.models.clone_model(model, clone_function=annotate_dense)\n",
        "qat_model = tfmot.quantization.keras.quantize_apply(annotated)  # Error: no layers annotated!\n",
        "```\n",
        "\n",
        "**Why it fails:**\n",
        "- `clone_model()` with `clone_function` only applies to **top-level layers**\n",
        "- Dense layers are **inside** custom layers (EncoderLayer, Projection, etc.)\n",
        "- `clone_function` never sees the nested Dense layers!\n",
        "\n",
        "**The Solution:**\n",
        "- Use `tfmot.quantization.keras.quantize_model()` - it traverses nested layers automatically\n",
        "- Or use `quantize_annotate_model()` - also handles nesting\n",
        "\n",
        "**That's why the test_export.py code was so complicated** - it was trying to manually solve this nesting problem. But we don't need to - tfmot's built-in functions handle it!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö†Ô∏è CRITICAL FINDING: Model‚ÜíModel Breaks QAT!\n",
        "\n",
        "**The Error:**\n",
        "```\n",
        "ValueError: Quantizing a keras Model inside another keras Model is not supported.\n",
        "```\n",
        "\n",
        "**What Happened:**\n",
        "- We made Encoder and Decoder into **Functional Models** for better visualization\n",
        "- This created: SignBART (Model) ‚Üí Encoder (Model) ‚Üí Decoder (Model)\n",
        "- **TensorFlow Model Optimization does NOT support nested Models!**\n",
        "\n",
        "**The Fix:**\n",
        "- ‚úÖ **REVERTED** Encoder and Decoder back to `layers.Layer` subclasses\n",
        "- Now: SignBART (Model) ‚Üí Encoder (Layer) ‚Üí Decoder (Layer) ‚úì\n",
        "\n",
        "**Trade-offs:**\n",
        "- ‚ùå Lost: Individual `.summary()` for Encoder/Decoder\n",
        "- ‚ùå Lost: Better Netron visualization\n",
        "- ‚úÖ Gained: **QAT compatibility** (most important!)\n",
        "- ‚úÖ Gained: Can still access nested Dense layers for selective quantization\n",
        "\n",
        "**Architecture that works with QAT:**\n",
        "```\n",
        "SignBART (Functional Model)\n",
        "‚îú‚îÄ‚îÄ Projection (Layer)\n",
        "‚îú‚îÄ‚îÄ Encoder (Layer)           ‚Üê Layer, not Model!\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ EncoderLayer (Layer)\n",
        "‚îÇ       ‚îú‚îÄ‚îÄ fc1 (Dense)\n",
        "‚îÇ       ‚îî‚îÄ‚îÄ fc2 (Dense)\n",
        "‚îú‚îÄ‚îÄ Decoder (Layer)           ‚Üê Layer, not Model!\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ DecoderLayer (Layer)\n",
        "‚îÇ       ‚îú‚îÄ‚îÄ fc1 (Dense)\n",
        "‚îÇ       ‚îî‚îÄ‚îÄ fc2 (Dense)\n",
        "‚îî‚îÄ‚îÄ ClassificationHead (Layer)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*100)\n",
        "print(\"REBUILDING MODEL WITH LAYER-BASED ENCODER/DECODER\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "# Rebuild the model (it will now use Layer-based Encoder/Decoder)\n",
        "from importlib import reload\n",
        "import model_functional\n",
        "reload(model_functional)\n",
        "\n",
        "model = model_functional.build_signbart_functional_with_dict_inputs(config)\n",
        "\n",
        "# Test it still works\n",
        "output = model(dummy_input, training=False)\n",
        "print(f\"‚úì Model rebuilt successfully\")\n",
        "print(f\"  Output shape: {output.shape}\")\n",
        "\n",
        "# Check the architecture\n",
        "print(\"\\n‚úì Verifying architecture:\")\n",
        "for layer in model.layers:\n",
        "    layer_type = \"Model\" if isinstance(layer, keras.Model) else \"Layer\"\n",
        "    print(f\"  - {layer.name:30s} ({layer_type})\")\n",
        "    \n",
        "print(\"\\n‚úì No nested Models - QAT should work now!\")\n",
        "print(\"=\"*100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*100)\n",
        "print(\"TESTING QAT AGAIN (with Layer-based Encoder/Decoder)\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "print(\"\\nApproach 1: quantize_model() - ONE LINE!\")\n",
        "try:\n",
        "    qat_model = tfmot.quantization.keras.quantize_model(model)\n",
        "    print(\"‚úì SUCCESS!\")\n",
        "    print(f\"  Total params: {qat_model.count_params():,}\")\n",
        "    \n",
        "    # Test forward pass\n",
        "    test_output = qat_model(dummy_input, training=False)\n",
        "    print(f\"‚úì Forward pass works, output shape: {test_output.shape}\")\n",
        "    \n",
        "    print(\"\\nüéâ QAT WORKS with Layer-based architecture!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå FAILED: {type(e).__name__}: {str(e)[:200]}\")\n",
        "    qat_model = None\n",
        "\n",
        "print(\"=\"*100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Lessons Learned\n",
        "\n",
        "### ‚úÖ What Works for QAT:\n",
        "1. **Architecture:** Model ‚Üí Layer ‚Üí Layer (NO nested Models!)\n",
        "2. **Method:** `tfmot.quantization.keras.quantize_model(model)` - one line!\n",
        "3. **Simplicity:** tfmot handles nested layers automatically\n",
        "\n",
        "### ‚ùå What Breaks QAT:\n",
        "1. **Nested Models:** Model ‚Üí Model ‚Üí Layer\n",
        "2. **Manual clone_model():** Doesn't traverse nested custom layers\n",
        "3. **Complex workarounds:** Not needed!\n",
        "\n",
        "### üéØ Final Answer to \"Is test_export.py code correct?\"\n",
        "\n",
        "**Answer:** No - it's **too complicated** and uses an outdated approach.\n",
        "\n",
        "**The simple version:**\n",
        "```python\n",
        "# That's it! One line!\n",
        "qat_model = tfmot.quantization.keras.quantize_model(model)\n",
        "```\n",
        "\n",
        "**What it does automatically:**\n",
        "- Finds all Dense layers (even nested ones)\n",
        "- Annotates them for quantization\n",
        "- Skips non-quantizable layers\n",
        "- Handles custom Layer subclasses properly\n",
        "\n",
        "**When you need more control:**\n",
        "Use `DefaultN8QuantizeConfig` to customize what gets quantized (we'll explore this next).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.2 Working Strategy: Quantize Only Dense Layers\n",
        "\n",
        "We‚Äôll annotate only the `Dense` layers (fc1/fc2, classification head, etc.) while everything else (Projection, Attention, LayerNorm, etc.) stays FP32.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*100)\n",
        "print(\"SELECTIVE QAT: Annotate ONLY Dense layers\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "# Import custom layers for clone_model scope\n",
        "from layers import Projection, ClassificationHead, PositionalEmbedding\n",
        "from encoder import Encoder, EncoderLayer\n",
        "from decoder import Decoder, DecoderLayer\n",
        "from attention import SelfAttention, CrossAttention, CausalSelfAttention\n",
        "from model_functional import ExtractLastValidToken\n",
        "\n",
        "custom_objects = {\n",
        "    'Projection': Projection,\n",
        "    'ClassificationHead': ClassificationHead,\n",
        "    'PositionalEmbedding': PositionalEmbedding,\n",
        "    'Encoder': Encoder,\n",
        "    'EncoderLayer': EncoderLayer,\n",
        "    'Decoder': Decoder,\n",
        "    'DecoderLayer': DecoderLayer,\n",
        "    'SelfAttention': SelfAttention,\n",
        "    'CrossAttention': CrossAttention,\n",
        "    'CausalSelfAttention': CausalSelfAttention,\n",
        "    'ExtractLastValidToken': ExtractLastValidToken,\n",
        "}\n",
        "\n",
        "# Clone function that only annotates Dense layers\n",
        "\n",
        "def annotate_only_dense(layer):\n",
        "    if isinstance(layer, keras.layers.Dense):\n",
        "        print(f\"  Annotating Dense layer: {layer.name}\")\n",
        "        return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "    return layer\n",
        "\n",
        "print(\"\\nStep 1: Annotating Dense layers (others untouched)...\")\n",
        "with keras.utils.custom_object_scope(custom_objects):\n",
        "    annotated_dense_model = keras.models.clone_model(\n",
        "        model,\n",
        "        clone_function=annotate_only_dense\n",
        "    )\n",
        "print(\"‚úì Annotation complete\")\n",
        "\n",
        "print(\"\\nStep 2: Applying quantization...\")\n",
        "with keras.utils.custom_object_scope({**custom_objects}):\n",
        "    qat_dense_model = tfmot.quantization.keras.quantize_apply(annotated_dense_model)\n",
        "print(\"‚úì QAT model created with Dense-only quantization\")\n",
        "\n",
        "# Quick sanity check\n",
        "output = qat_dense_model(dummy_input, training=False)\n",
        "print(f\"\\n‚úì Forward pass OK, output shape: {output.shape}\")\n",
        "\n",
        "print(\"=\"*100)\n",
        "print(\"RESULT\")\n",
        "print(\"=\"*100)\n",
        "print(\"- Dense layers (fc1/fc2, classification head) are quantized\")\n",
        "print(\"- Projection, attention, layernorm, etc. remain FP32\")\n",
        "print(\"- No custom QuantizeConfig needed\")\n",
        "print(\"=\"*100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_all_dense_layers(layer, path=\"\", indent=0):\n",
        "    \"\"\"Recursively find all Dense layers in a model or layer.\"\"\"\n",
        "    prefix = \"  \" * indent\n",
        "    \n",
        "    if isinstance(layer, keras.layers.Dense):\n",
        "        params = sum([tf.size(w).numpy() for w in layer.trainable_variables])\n",
        "        print(f\"{prefix}‚úì Dense: {path}/{layer.name} ({params:,} params)\")\n",
        "        return 1\n",
        "    \n",
        "    count = 0\n",
        "    \n",
        "    # First check if layer has .layers attribute (standard Keras)\n",
        "    if hasattr(layer, 'layers') and layer.layers:\n",
        "        print(f\"{prefix}üì¶ {layer.__class__.__name__}: {path}/{layer.name}\")\n",
        "        for sublayer in layer.layers:\n",
        "            sublayer_path = f\"{path}/{layer.name}\" if path else layer.name\n",
        "            count += find_all_dense_layers(sublayer, sublayer_path, indent + 1)\n",
        "    \n",
        "    # Also check for Dense layers stored as attributes (custom layers)\n",
        "    # This is needed for Projection, ClassificationHead, etc.\n",
        "    else:\n",
        "        print(f\"{prefix}üì¶ {layer.__class__.__name__}: {path}/{layer.name}\")\n",
        "        for attr_name in dir(layer):\n",
        "            if attr_name.startswith('_'):\n",
        "                continue\n",
        "            try:\n",
        "                attr = getattr(layer, attr_name)\n",
        "                if isinstance(attr, keras.layers.Layer):\n",
        "                    sublayer_path = f\"{path}/{layer.name}\" if path else layer.name\n",
        "                    count += find_all_dense_layers(attr, sublayer_path, indent + 1)\n",
        "            except:\n",
        "                pass\n",
        "    \n",
        "    return count\n",
        "\n",
        "print(\"\\nFinding all Dense layers in the model...\")\n",
        "print(\"=\"*80)\n",
        "total_dense = find_all_dense_layers(model)\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nTotal Dense layers found: {total_dense}\")\n",
        "\n",
        "# Also show what layers can be quantized\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"QUANTIZABLE LAYERS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(\"These Dense layers can be selectively quantized:\")\n",
        "print(\"  ‚Ä¢ proj_x1, proj_y1 - Projection layers (keypoint embedding)\")\n",
        "print(\"  ‚Ä¢ q_proj, k_proj, v_proj, out_proj - Attention projections\")\n",
        "print(\"  ‚Ä¢ fc1, fc2 - Feed-forward network (FFN)\")\n",
        "print(\"  ‚Ä¢ out_proj (in clf_head) - Classification output\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. QAT Strategy 1: Quantize ALL Dense Layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STRATEGY 1: Quantize ALL Dense Layers\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def annotate_all_dense(layer):\n",
        "    \"\"\"Annotate all Dense layers for quantization.\"\"\"\n",
        "    if isinstance(layer, keras.layers.Dense):\n",
        "        print(f\"  ‚úì Annotating: {layer.name}\")\n",
        "        return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "    return layer\n",
        "\n",
        "print(\"\\nAnnotating Dense layers...\")\n",
        "annotated_model_1 = keras.models.clone_model(\n",
        "    model,\n",
        "    clone_function=annotate_all_dense\n",
        ")\n",
        "\n",
        "print(\"\\nApplying quantization...\")\n",
        "qat_model_1 = tfmot.quantization.keras.quantize_apply(annotated_model_1)\n",
        "\n",
        "print(\"\\n‚úì QAT Model 1 created\")\n",
        "print(f\"  Total params: {qat_model_1.count_params():,}\")\n",
        "\n",
        "# Test inference\n",
        "qat_output_1 = qat_model_1(dummy_input, training=False)\n",
        "print(f\"  ‚úì Inference works! Output shape: {qat_output_1.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. QAT Strategy 2: Quantize Only FFN (fc1/fc2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STRATEGY 2: Quantize Only FFN (fc1/fc2) Dense Layers\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def annotate_ffn_only(layer):\n",
        "    \"\"\"Annotate only FFN Dense layers (fc1, fc2).\"\"\"\n",
        "    if isinstance(layer, keras.layers.Dense):\n",
        "        # Only quantize fc1 and fc2 (feed-forward network)\n",
        "        if 'fc1' in layer.name or 'fc2' in layer.name:\n",
        "            print(f\"  ‚úì Annotating: {layer.name}\")\n",
        "            return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "        else:\n",
        "            print(f\"  ‚äó Skipping: {layer.name} (not FFN)\")\n",
        "    return layer\n",
        "\n",
        "print(\"\\nAnnotating FFN Dense layers only...\")\n",
        "annotated_model_2 = keras.models.clone_model(\n",
        "    model,\n",
        "    clone_function=annotate_ffn_only\n",
        ")\n",
        "\n",
        "print(\"\\nApplying quantization...\")\n",
        "qat_model_2 = tfmot.quantization.keras.quantize_apply(annotated_model_2)\n",
        "\n",
        "print(\"\\n‚úì QAT Model 2 created\")\n",
        "print(f\"  Total params: {qat_model_2.count_params():,}\")\n",
        "\n",
        "# Test inference\n",
        "qat_output_2 = qat_model_2(dummy_input, training=False)\n",
        "print(f\"  ‚úì Inference works! Output shape: {qat_output_2.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Compare Outputs - Which Strategy Maintains Accuracy?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"OUTPUT COMPARISON - Numerical Equivalence Check\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Generate test input\n",
        "test_input = {\n",
        "    'keypoints': tf.random.normal((2, 15, num_keypoints, 2)),\n",
        "    'attention_mask': tf.ones((2, 15))\n",
        "}\n",
        "\n",
        "# Get outputs\n",
        "base_output = model(test_input, training=False).numpy()\n",
        "qat1_output = qat_model_1(test_input, training=False).numpy()\n",
        "qat2_output = qat_model_2(test_input, training=False).numpy()\n",
        "\n",
        "# Compare\n",
        "print(f\"\\n{'Comparison':<25} {'Max Diff':<15} {'Mean Diff':<15} {'Status'}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "def compare_outputs(name, qat_out, base_out):\n",
        "    max_diff = np.abs(qat_out - base_out).max()\n",
        "    mean_diff = np.abs(qat_out - base_out).mean()\n",
        "    status = \"‚úì Good\" if max_diff < 1e-3 else \"‚ö† Large diff\"\n",
        "    print(f\"{name:<25} {max_diff:<15.6e} {mean_diff:<15.6e} {status}\")\n",
        "\n",
        "compare_outputs(\"QAT-1 vs Base\", qat1_output, base_output)\n",
        "compare_outputs(\"QAT-2 vs Base\", qat2_output, base_output)\n",
        "\n",
        "print(\"\\n‚ö† Note: Small differences are expected due to fake quantization\")\n",
        "print(\"   These simulate INT8 quantization effects during training\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9.5 IMPORTANT: Correct TFLite Conversion\n",
        "\n",
        "**‚ö†Ô∏è Common Mistake:**\n",
        "```python\n",
        "# WRONG ‚ùå - Don't do this!\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "```\n",
        "\n",
        "**Why it's wrong:**\n",
        "1. Doesn't handle dict inputs properly\n",
        "2. Can't handle dynamic shapes (None, None, ...)\n",
        "3. TFLite needs FIXED input shapes\n",
        "\n",
        "**‚úÖ Correct approach (from main_functional.py):**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*100)\n",
        "print(\"CORRECT TFLITE CONVERSION\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "# Step 1: Define FIXED input shape\n",
        "MAX_SEQ_LEN = 64  # Fixed sequence length for TFLite (covers 99%+ of data)\n",
        "num_keypoints = len(config['joint_idx'])\n",
        "\n",
        "print(f\"\\nFixed input shape for TFLite:\")\n",
        "print(f\"  keypoints: [1, {MAX_SEQ_LEN}, {num_keypoints}, 2]\")\n",
        "print(f\"  attention_mask: [1, {MAX_SEQ_LEN}]\")\n",
        "\n",
        "# Step 2: Create concrete function with input signature\n",
        "@tf.function(input_signature=[\n",
        "    {\n",
        "        'keypoints': tf.TensorSpec(shape=[1, MAX_SEQ_LEN, num_keypoints, 2], dtype=tf.float32),\n",
        "        'attention_mask': tf.TensorSpec(shape=[1, MAX_SEQ_LEN], dtype=tf.float32)\n",
        "    }\n",
        "])\n",
        "def model_predict(inputs):\n",
        "    return model(inputs, training=False)\n",
        "\n",
        "print(\"\\n‚úì Created concrete function with fixed input signature\")\n",
        "\n",
        "# Step 3: Convert from concrete function (NOT from_keras_model!)\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions(\n",
        "    [model_predict.get_concrete_function()]\n",
        ")\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS  # Allows select TF ops for unsupported operations\n",
        "]\n",
        "\n",
        "print(\"\\n‚úì Converter configured\")\n",
        "print(\"  Supported ops: TFLITE_BUILTINS + SELECT_TF_OPS\")\n",
        "\n",
        "# Step 4: Convert\n",
        "print(\"\\nConverting to TFLite...\")\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Step 5: Save\n",
        "fp32_tflite_path = \"test_fp32.tflite\"\n",
        "with open(fp32_tflite_path, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "tflite_size_mb = len(tflite_model) / (1024**2)\n",
        "print(f\"‚úì TFLite model saved: {fp32_tflite_path}\")\n",
        "print(f\"  Size: {tflite_size_mb:.2f} MB\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"KEY DIFFERENCES:\")\n",
        "print(\"=\"*100)\n",
        "print(\"‚ùå from_keras_model(model)        ‚Üí Fails with dict inputs + dynamic shapes\")\n",
        "print(\"‚úÖ from_concrete_functions([...]) ‚Üí Works with fixed signature\")\n",
        "print(\"\\n‚ùå Dynamic shape: (None, None, 90, 2)  ‚Üí TFLite can't handle\")\n",
        "print(f\"‚úÖ Fixed shape: (1, {MAX_SEQ_LEN}, {num_keypoints}, 2)      ‚Üí TFLite compatible\")\n",
        "print(\"=\"*100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Test Training - Can We Actually Train With QAT?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TESTING QAT MODEL TRAINING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Pick strategy 2 (conservative)\n",
        "test_qat_model = qat_model_2\n",
        "\n",
        "# Compile\n",
        "print(\"\\nCompiling QAT model...\")\n",
        "test_qat_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=2e-4),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "print(\"‚úì Model compiled\")\n",
        "\n",
        "# Create fake training data\n",
        "print(\"\\nCreating fake training batch...\")\n",
        "fake_batch_size = 4\n",
        "fake_seq_len = 20\n",
        "\n",
        "fake_inputs = {\n",
        "    'keypoints': tf.random.normal((fake_batch_size, fake_seq_len, num_keypoints, 2)),\n",
        "    'attention_mask': tf.ones((fake_batch_size, fake_seq_len))\n",
        "}\n",
        "fake_labels = tf.random.uniform((fake_batch_size,), minval=0, maxval=config['num_labels'], dtype=tf.int32)\n",
        "\n",
        "print(\"\\nTesting training step...\")\n",
        "history = test_qat_model.fit(\n",
        "    fake_inputs,\n",
        "    fake_labels,\n",
        "    batch_size=fake_batch_size,\n",
        "    epochs=2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n‚úì‚úì‚úì QAT MODEL TRAINING WORKS! ‚úì‚úì‚úì\")\n",
        "print(\"\\nYou can now integrate this strategy into main_functional.py\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Code Template - Copy This Into main_functional.py\n",
        "\n",
        "Once you've chosen your strategy, use this template to integrate QAT into training:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\"\"\n",
        "CODE TO ADD TO main_functional.py:\n",
        "================================================================================\n",
        "\n",
        "# 1. Add import at top:\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "# 2. Add argument to parser:\n",
        "parser.add_argument(\"--qat\", action=\"store_true\",\n",
        "                    help=\"Enable Quantization-Aware Training\")\n",
        "\n",
        "# 3. After building model, before compiling (around line 110):\n",
        "if args.qat:\n",
        "    print(\"\\\\nApplying QAT...\")\n",
        "    \n",
        "    def annotate_for_qat(layer):\n",
        "        # Strategy 2: FFN only (conservative, best accuracy)\n",
        "        if isinstance(layer, keras.layers.Dense):\n",
        "            if 'fc1' in layer.name or 'fc2' in layer.name:\n",
        "                return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "        return layer\n",
        "    \n",
        "    annotated_model = keras.models.clone_model(\n",
        "        model,\n",
        "        clone_function=annotate_for_qat\n",
        "    )\n",
        "    model = tfmot.quantization.keras.quantize_apply(annotated_model)\n",
        "    print(\"‚úì QAT applied (FFN layers quantized)\")\n",
        "\n",
        "# Then continue with model.compile() as usual...\n",
        "\n",
        "================================================================================\n",
        "\n",
        "USAGE:\n",
        "python train_loso_functional.py \\\\\n",
        "    --config_path configs/arabic-asl-90kpts.yaml \\\\\n",
        "    --base_data_path ~/signbart_tf/data/arabic-asl-90kpts \\\\\n",
        "    --holdout_only user01 \\\\\n",
        "    --epochs 2 \\\\\n",
        "    --lr 2e-4 \\\\\n",
        "    --qat  # <-- Add this flag!\n",
        "\"\"\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
